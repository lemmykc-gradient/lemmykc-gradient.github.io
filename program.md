---
layout: default
title: Australian AI Safety Forum
---

# ADDRESS ?? What is it! 

## Day 1 - Thursday 7th November

| Time | Room | Session | Speakers |
|------|------|---------|-----------|
| 08:00 | | Registration and free barista coffee cart | |
| 09:00 | 277 | **Opening of the inaugural Australian AI Safety Forum** | **Helen Wilson**, Deputy Secretary - Commonwealth Department of Industry, Science, and Resources |
| 09:05 | 277 | **Welcome to Sydney Knowledge Hub** | **Karla Perez Romero**, Sydney Knowledge Hub |
| 09:10 | 277 | **Welcome to AI Safety Forum** | **Liam Carroll**, Gradient Institute and Timaeus |
| 09:30 | 277 | **State of AI** | **Tiberio Caetano**, Gradient Institute |
| 10:00 | 277 | **State of Technical AI safety** | **Daniel Murfet**, University of Melbourne |
| 10:30 | 277 | **State of AI Governance** | **Kimberlee Weatherall**, University of Sydney |
| 11:00 | | Morning tea | |
| 11:30 | 277 | **Keynote: Red-Teaming for Generative AI - Silver Bullet or Security Theater** | **Hoda Heidari**, Carnegie Mellon University |
| 12:15 | 277 | **Keynote: Accelerating AI Safety Talent** | **Ryan Kidd**, MATS Research |
| 13:00 | | Lunch | |
| 14:00 | 277 | **Keynote: Frontier AI Safety Governance: Open Questions** | **Seth Lazar**, Australian National University |
| 14:45 | 277 | **Keynote: AGI Safety via AIXI** | **Marcus Hutter**, Australian National University |
| 15:30 | | Afternoon tea | |
| 16:00 | 277 | **Panel discussion** | **Tiberio Caetano**, Gradient Institute<br>**Marcus Hutter**, Australian National University<br>**Ryan Kidd**, MATS Research<br>**Seth Lazar**, Australian National University<br>**Kimberlee Weatherall**, University of Sydney |
| 17:00 | | Networking and drinks | |
| 18:30 | | _END Day 1_ | |

## Day 2 - Friday 8th November

| Time | Room | Session | Convenors | Description |
|------|------|---------|-----------|-------------|
| 08:30 | | Doors open | | |
| 09:00 | 277 | **Introduction to Day 2** | **Liam Carroll**, Gradient Institute and Timaeus |  |
| 09:05 | 277 | **State of the science: The International Scientific Report on the Safety of Advanced AI** | **Daniel Murfet**, University of Melbourne<br>**Tiberio Caetano**, Gradient Institute | The International Scientific Report on the Safety of Advanced AI describes the capabilities, risks, and technical approaches to address risks of increasingly capable general-purpose AI systems. In this session we will explore the best current scientific understanding of AI safety including critical challenges and emerging approaches for making progress. |
| 10:30 | | Morning tea | | |
| 11:00 | 277 | **International governance of AI safety: a role for Australia?** | **Johanna Weaver**, Tech Policy Design Centre<br>**Kimberlee Weatherall**, University of Sydney | Many countries and institutions are enacting laws or multilateral agreements about how to develop and use AI. In this session, learn about the latest international processes, laws and proposals, explore their relevance to the Australian context, and discuss how Australia might participate in international governance for AI safety. |
| 11:00 | 275 | **Unpacking "Safe" and "Responsible" AI** | **Qinghua Lu**, CSIRO<br>**Alexander Saeri**, MIT FutureTech | Responsible AI and AI Safety are often discussed together, but what is the relationship between these concepts and communities? In this session, we will provide an overview of recent progress in the science of Responsible AI, and provide space to discuss cross-pollination between Responsible AI and AI Safety research & practice communities. |
| 11:00 | 273 | **Perspectives on generalisation in the science of AI safety** | **Daniel Murfet**, University of Melbourne<br>**Marcus Hutter**, Australian National University | Understanding how AI models learn and generalise is necessary for designing, building, and deploying AI safely. In this session, Daniel Murfet and Marcus Hutter explore mathematical frameworks that illuminate AI behaviour, with implications for technical approaches to AI safety. |
| 12:00 | 277 | **New Governance Proposals for Frontier AI Safety** | **Keynote, Atoosa Kasirzadeh**, Carnegie Mellon University<br>**Seth Lazar**, Australian National University<br>**Kimberlee Weatherall**, University of Sydney | Governing the most advanced 'frontier' AI systems presents unique challenges beyond general AI governance. In this session we will discuss responsible scaling policies, compute governance, open source development, governing autonomous agents, and pre-release testing. We will examine the political and social dimensions of frontier AI governance and explore trade-offs in governance strategies for highly capable AI systems. |
| 12:00 | 275 | **Emerging practice in technical AI safety** | **Soroush Pour**, Harmony Intelligence<br>**Ryan Kidd**, MATS Research<br>**Liam Carroll**, Gradient Institute and Timaeus | This session explores concrete initiatives in technical AI safety through AI evaluations development, talent cultivation, and research acceleration. Join Soroush Pour from Harmony Intelligence and Ryan Kidd from MATS Research as they share their experiences building concrete AI safety projects and programs, followed by open discussion. |
| 13:00 | | Lunch | | |
| 14:00 | 277 | **What could an Australian AI Safety Institute look like?** | **Greg Sadler**, Good Ancestors Policy<br>**Keynote, Nitarshan Rajkumar**, University of Cambridge | The UK, US, Japan and others have established AI Safety Institutes to research and support action on risks from AI. In this session, we will discuss what an Australian AISI could do, how this could advance AI safety in Australia and internationally, and how such an Institute could operate. |
| 15:50 | 277 | **Concluding remarks** | **Liam Carroll**, Gradient Institute and Timaeus | |
| 15:55 | | _END Day 2_ | | |