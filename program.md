---
layout: default
title: Australian AI Safety Forum
---

## Day 1 - Thursday 7th November

| Time | Room | Session | Speakers |
|------|------|---------|-----------|
| 08:00 | | **Registration and free barista coffee cart** | |
| 09:00 | 277 | **Welcome and Introduction to Day 1** | **Liam Carroll**, Gradient Institute and Timaeus<br>**Helen Wilson**, Commonwealth Department of Industry, Science, and Resources<br>**Karla Perez Romero**, Sydney Knowledge Hub |
| 09:30 | 277 | **Primer lecture: State of AI** | **Tiberio Caetano**, Gradient Institute |
| 10:00 | 277 | **Primer lecture: State of technical AI safety** | **Daniel Murfet**, University of Melbourne |
| 10:30 | 277 | **Primer lecture: State of AI governance** | **Kimberlee Weatherall**, University of Sydney |
| 11:00 | | Morning tea | |
| 11:30 | 277 | **Red-Teaming for Generative AI: Silver Bullet or Security Theater** | **Hoda Heidari**, Carnegie Mellon University |
| 12:15 | 277 | **Accelerating AI Safety Talent** | **Ryan Kidd**, MATS Research |
| 13:00 | | Lunch | |
| 14:00 | 277 | **Frontier AI Safety Governance: Open Questions** | **Seth Lazar**, Australian National University |
| 14:45 | 277 | **Foundations of Artificial Intelligence and AI Safety** | **Marcus Hutter**, Australian National University |
| 15:30 | | Afternoon tea | |
| 16:00 | 277 | **Panel discussion** | **Tiberio Caetano**, Gradient Institute<br>**Marcus Hutter**, Australian National University<br>**Ryan Kidd**, MATS Research<br>**Seth Lazar**, Australian National University<br>**Kimberlee Weatherall**, University of Sydney |
| 17:00 | | Networking and drinks | |
| 18:30 | | END Day 1 | |

## Day 2 - Friday 8th November

| Time | Room | Session | Speakers | Description |
|------|------|---------|-----------|-------------|
| 08:30 | | Doors open | | |
| 09:00 | 277 | **Introduction to Day 2** | **Liam Carroll**, Gradient Institute and Timaeus | The International Scientific Report on the Safety of Advanced AI describes the capabilities, risks, and technical approaches to address risks of increasingly capable general-purpose AI systems. In this session we will explore the best current scientific understanding of AI safety including the most important challenges and the most promising methods for making progress. |
| 09:00 | 277 | **State of the science: The International Scientific Report on the Safety of Advanced AI** | **Daniel Murfet**, University of Melbourne<br>**Marcus Hutter**, Australian National University | |
| 10:30 | | Morning tea | | |
| 11:00 | 277 | **International governance of AI safety: a role for Australia?** | **Johanna Weaver**, Tech Policy Design Centre<br>**Kimberlee Weatherall**, University of Sydney | Many countries and institutions are enacting laws or multilateral agreements about how to develop and use AI. In this session, learn about the latest international processes, laws and proposals, explore their relevance to the Australian context, and discuss how Australia might participate in international governance for AI safety. |
| 11:00 | 275 | **Unpacking "Safe" and "Responsible" AI** | **Qinghua Lu**, CSIRO<br>**Alexander Saeri**, MIT FutureTech | Responsible AI and AI Safety are often discussed together, but what is the relationship between these concepts and communities? In this session, we will provide an overview of recent progress in the science of Responsible AI, and provide space to discuss cross-pollination between Responsible AI and AI Safety research & practice communities. |
| 11:00 | 273 | **Perspectives on generalisation in the science of AI safety** | **Daniel Murfet**, University of Melbourne<br>**Marcus Hutter**, Australian National University | Understanding how AI models learn and generalise is necessary for designing, building, and deploying AI safely. In this session, Daniel Murfet and Marcus Hutter explore mathematical frameworks that illuminate AI behaviour, with implications for technical approaches to AI safety. |
| 12:00 | 277 | **New Governance Proposals for Frontier AI Safety** | **Seth Lazar**, Australian National University<br>**Atoosa Kasirzadeh**, Carnegie Mellon University<br>**Kimberlee Weatherall**, University of Sydney | Governing the most advanced 'frontier' AI systems presents unique challenges beyond general AI governance. In this session we will discuss responsible scaling policies, compute governance, open source development, governing autonomous agents, and pre-release testing. We will examine the political and social dimensions of frontier AI governance and explore trade-offs in governance strategies for highly capable AI systems. |
| 12:00 | 275 | **Emerging practice in technical AI safety** | **Soroush Pour**, Harmony Intelligence<br>**Ryan Kidd**, MATS Research<br>**Liam Carroll**, Gradient Institute and Timaeus | This session explores concrete initiatives in technical AI safety through AI evaluations development, talent cultivation, and research acceleration. Join Soroush Pour from Harmony Intelligence and Ryan Kidd from MATS Research as they share their experiences building concrete AI safety projects and programs, followed by open discussion. |
| 12:00 | 273 | **Wildcard session** | **Alexander Saeri**, MIT FutureTech | The topic of this session will be selected by Forum attendees on Day 1. |
| 13:00 | | Lunch | | |
| 14:00 | 277 | **What could an Australian AI Safety Institute look like?** | **Nitarshan Rajkumar**, University of Cambridge<br>**Greg Sadler**, Good Ancestors Policy | The UK, US, Japan and others have established AI Safety Institutes to research and support action on risks from AI. In this session, we will discuss what an Australian AISI could do, how this could advance AI safety in Australia and internationally, and how such an Institute could operate. |
| 15:50 | 277 | **Concluding remarks** | **Liam Carroll**, Gradient Institute and Timaeus | |
| 15:55 | | END Day 2 | | |